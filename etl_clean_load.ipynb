{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c266a728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos limpios guardados en data\\clean.pkl — filas: 414\n"
     ]
    }
   ],
   "source": [
    "# etl_clean_load.py\n",
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATA_DIR = \"data\"\n",
    "RAW_PATH = os.path.join(DATA_DIR, \"raw.csv\")\n",
    "CLEAN_PATH = os.path.join(DATA_DIR, \"clean.pkl\")\n",
    "\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "if not os.path.exists(RAW_PATH):\n",
    "    raise FileNotFoundError(f\"No se encontró {RAW_PATH}. Ejecuta primero generate_synthetic.py\")\n",
    "\n",
    "# ------------------ helpers ------------------\n",
    "\n",
    "def strip_accents(s: str) -> str:\n",
    "    \"\"\"Elimina acentos/diacríticos (útil para validar emails con unicode).\"\"\"\n",
    "    s = str(s)\n",
    "    return \"\".join(c for c in unicodedata.normalize(\"NFKD\", s) if not unicodedata.combining(c))\n",
    "\n",
    "def parse_amount(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    s = str(x)\n",
    "    s = re.sub(r\"[^0-9.,-]\", \"\", s)  # quitar símbolos\n",
    "    s = s.replace(\",\", \".\")\n",
    "    try:\n",
    "        return float(s)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "def parse_date(x):\n",
    "    for fmt in (\"%Y-%m-%d\", \"%d-%m-%Y\", \"%d/%m/%Y\"):\n",
    "        try:\n",
    "            return datetime.strptime(str(x), fmt)\n",
    "        except Exception:\n",
    "            continue\n",
    "    return pd.NaT\n",
    "\n",
    "# ------------------ carga cruda ------------------\n",
    "\n",
    "df = pd.read_csv(RAW_PATH, dtype=str)\n",
    "\n",
    "# ------------------ normalizaciones ------------------\n",
    "\n",
    "df.columns = [c.strip().lower() for c in df.columns]\n",
    "df[\"name\"] = df[\"name\"].astype(str).str.strip()\n",
    "df[\"email\"] = df[\"email\"].astype(str).str.strip().str.lower()\n",
    "\n",
    "# para validación quitamos acentos (sin modificar el email original)\n",
    "email_for_validation = df[\"email\"].apply(strip_accents)\n",
    "\n",
    "df[\"country\"] = (\n",
    "    df[\"country\"].astype(str).str.strip().str.upper()\n",
    "    .replace({\"NONE\": np.nan, \"NAN\": np.nan, \"\": np.nan})\n",
    ")\n",
    "\n",
    "# user_id numérico\n",
    "df[\"user_id\"] = pd.to_numeric(df[\"user_id\"], errors=\"coerce\")\n",
    "\n",
    "# amount y fechas\n",
    "df[\"amount\"] = df[\"amount\"].apply(parse_amount)\n",
    "df[\"created_at\"] = df[\"created_at\"].apply(parse_date)\n",
    "\n",
    "# ------------------ validaciones ------------------\n",
    "\n",
    "# Regex permisiva: acepta unicode en local/domain (sin espacios y con TLD >=2)\n",
    "email_re = re.compile(r\"^[^@\\s]+@[^@\\s]+\\.[^@\\s]{2,}$\")\n",
    "df[\"email_valid\"] = email_for_validation.apply(\n",
    "    lambda e: bool(email_re.match(str(e))) if pd.notna(e) else False\n",
    ")\n",
    "\n",
    "# catálogo de países (los no incluidos se van a NaN)\n",
    "valid_countries = {\"PE\", \"MX\", \"CO\", \"AR\"}\n",
    "df[\"country\"] = df[\"country\"].apply(lambda c: c if c in valid_countries else np.nan)\n",
    "\n",
    "# duplicados exactos\n",
    "df = df.drop_duplicates(subset=[\"user_id\", \"email\", \"created_at\"], keep=\"first\")\n",
    "\n",
    "# ------------------ reglas de calidad ------------------\n",
    "\n",
    "# Estricto: user_id + fecha + email válido\n",
    "filtered = df[(df[\"user_id\"].notna()) & (df[\"created_at\"].notna()) & (df[\"email_valid\"])]\n",
    "\n",
    "# Fallback si quedó vacío: relajar email para no devolver 0 filas\n",
    "if filtered.empty:\n",
    "    print(\"[AVISO] 0 filas tras filtro estricto. Relajando condición de email_valid…\")\n",
    "    filtered = df[(df[\"user_id\"].notna()) & (df[\"created_at\"].notna())]\n",
    "\n",
    "# ------------------ guardar ------------------\n",
    "\n",
    "filtered.to_pickle(CLEAN_PATH, protocol=4)\n",
    "print(f\"Datos limpios guardados en {CLEAN_PATH} — filas: {len(filtered)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_banco_digital",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
